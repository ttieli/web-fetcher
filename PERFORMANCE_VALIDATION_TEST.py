#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–éªŒè¯æµ‹è¯•è„šæœ¬
æ¶æ„å¸ˆéªŒè¯å·¥å…· - ç”¨äºéªŒè¯æ€§èƒ½ä¼˜åŒ–çš„å®é™…æ•ˆæœ

æµ‹è¯•ç›®æ ‡:
1. éªŒè¯äººæ°‘ç½‘é¡µé¢å¤„ç†æ€§èƒ½
2. ç¡®è®¤è¶…æ—¶æœºåˆ¶æœ‰æ•ˆæ€§
3. æµ‹è¯•å†…å®¹æå–å®Œæ•´æ€§
4. éªŒè¯å…¶ä»–ç«™ç‚¹å…¼å®¹æ€§
"""

import time
import subprocess
import json
import sys
import os
import tempfile
import hashlib
from datetime import datetime

class PerformanceValidator:
    def __init__(self):
        self.test_results = []
        self.critical_issues = []
        
    def run_test(self, test_name, url, expected_behavior):
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        print(f"\n[TEST] {test_name}")
        print(f"  URL: {url}")
        print(f"  Expected: {expected_behavior}")
        
        start_time = time.time()
        temp_dir = tempfile.mkdtemp()
        output_file = os.path.join(temp_dir, 'output.md')
        
        try:
            # æ‰§è¡Œwebfetcher
            cmd = [
                'python3', 'webfetcher.py',
                url,
                '-o', temp_dir
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=10  # 10ç§’ç¡¬è¶…æ—¶
            )
            
            elapsed = time.time() - start_time
            
            # åˆ†æç»“æœ
            success = result.returncode == 0
            has_output = os.path.exists(output_file)
            output_size = os.path.getsize(output_file) if has_output else 0
            
            test_result = {
                'name': test_name,
                'url': url,
                'success': success,
                'elapsed_time': elapsed,
                'has_output': has_output,
                'output_size': output_size,
                'stderr': result.stderr if not success else None
            }
            
            # éªŒè¯å†…å®¹
            if has_output:
                with open(output_file, 'r') as f:
                    content = f.read()
                    test_result['content_hash'] = hashlib.md5(content.encode()).hexdigest()
                    test_result['line_count'] = len(content.splitlines())
                    
                    # ç‰¹å®šå†…å®¹éªŒè¯
                    if 'people.com.cn' in url:
                        # æ£€æŸ¥æ˜¯å¦æœ‰æ”¿æ²»å±€ä¼šè®®è®°å½•
                        has_meeting_records = 'æ”¿æ²»å±€' in content or 'ä¼šè®®' in content
                        test_result['has_expected_content'] = has_meeting_records
            
            self.test_results.append(test_result)
            
            # è¾“å‡ºæµ‹è¯•ç»“æœ
            status = "âœ… PASS" if success else "âŒ FAIL"
            print(f"  Status: {status}")
            print(f"  Time: {elapsed:.2f}s")
            print(f"  Output: {output_size} bytes, {test_result.get('line_count', 0)} lines")
            
            if elapsed > 5:
                self.critical_issues.append(f"Performance issue: {test_name} took {elapsed:.2f}s")
            
            if not success:
                self.critical_issues.append(f"Failed test: {test_name}")
                print(f"  Error: {result.stderr[:200]}")
                
        except subprocess.TimeoutExpired:
            elapsed = time.time() - start_time
            self.critical_issues.append(f"TIMEOUT: {test_name} exceeded 10s limit")
            print(f"  Status: âŒ TIMEOUT after {elapsed:.2f}s")
            self.test_results.append({
                'name': test_name,
                'url': url,
                'success': False,
                'timeout': True,
                'elapsed_time': elapsed
            })
        except Exception as e:
            self.critical_issues.append(f"Exception in {test_name}: {str(e)}")
            print(f"  Status: âŒ ERROR - {str(e)}")
            self.test_results.append({
                'name': test_name,
                'url': url,
                'success': False,
                'error': str(e)
            })
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_dir):
                subprocess.run(['rm', '-rf', temp_dir], capture_output=True)
    
    def run_validation_suite(self):
        """è¿è¡Œå®Œæ•´éªŒè¯å¥—ä»¶"""
        print("=" * 80)
        print("PERFORMANCE OPTIMIZATION VALIDATION TEST SUITE")
        print("=" * 80)
        print(f"Start Time: {datetime.now()}")
        
        # æµ‹è¯•ç”¨ä¾‹å®šä¹‰
        test_cases = [
            # 1. å…³é”®é—®é¢˜é¡µé¢ - äººæ°‘ç½‘
            {
                'name': 'People Daily - Political Bureau Meetings (Critical)',
                'url': 'http://cpc.people.com.cn/n/2012/1119/c352110-19621695.html',
                'expected': 'Should complete within 2 seconds with meeting records'
            },
            
            # 2. åŸºå‡†æµ‹è¯• - ç®€å•é¡µé¢
            {
                'name': 'Simple Page - Example.com',
                'url': 'http://example.com',
                'expected': 'Should complete quickly with minimal content'
            },
            
            # 3. å¤æ‚å†…å®¹é¡µé¢
            {
                'name': 'Complex News Site - Sina',
                'url': 'http://news.sina.com.cn',
                'expected': 'Should handle complex layout without timeout'
            },
            
            # 4. å¸¦è¡¨æ ¼çš„é¡µé¢ï¼ˆéäººæ°‘ç½‘ï¼‰
            {
                'name': 'Table Content - Generic',
                'url': 'https://www.w3schools.com/html/html_tables.asp',
                'expected': 'Should process tables normally'
            }
        ]
        
        # æ‰§è¡Œæµ‹è¯•
        for test_case in test_cases:
            self.run_test(
                test_case['name'],
                test_case['url'],
                test_case['expected']
            )
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("VALIDATION REPORT")
        print("=" * 80)
        
        # ç»Ÿè®¡æ•°æ®
        total_tests = len(self.test_results)
        passed_tests = sum(1 for t in self.test_results if t.get('success'))
        failed_tests = total_tests - passed_tests
        timeout_tests = sum(1 for t in self.test_results if t.get('timeout'))
        
        avg_time = sum(t.get('elapsed_time', 0) for t in self.test_results) / total_tests if total_tests > 0 else 0
        
        print(f"\nTest Summary:")
        print(f"  Total Tests: {total_tests}")
        print(f"  Passed: {passed_tests} ({passed_tests/total_tests*100:.1f}%)")
        print(f"  Failed: {failed_tests}")
        print(f"  Timeouts: {timeout_tests}")
        print(f"  Average Time: {avg_time:.2f}s")
        
        # æ€§èƒ½åˆ†æ
        print(f"\nPerformance Analysis:")
        for result in self.test_results:
            name = result['name']
            time_taken = result.get('elapsed_time', 0)
            status = "âœ…" if result.get('success') else "âŒ"
            print(f"  {status} {name}: {time_taken:.2f}s")
        
        # å…³é”®é—®é¢˜
        if self.critical_issues:
            print(f"\nâš ï¸  CRITICAL ISSUES FOUND:")
            for issue in self.critical_issues:
                print(f"  - {issue}")
        else:
            print(f"\nâœ… No critical issues found")
        
        # æ¶æ„è¯„ä¼°
        print(f"\nğŸ—ï¸  ARCHITECTURE ASSESSMENT:")
        self.assess_architecture()
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        report_file = f'validation_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(report_file, 'w') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'summary': {
                    'total': total_tests,
                    'passed': passed_tests,
                    'failed': failed_tests,
                    'timeouts': timeout_tests,
                    'avg_time': avg_time
                },
                'results': self.test_results,
                'critical_issues': self.critical_issues
            }, f, indent=2)
        
        print(f"\nDetailed report saved to: {report_file}")
    
    def assess_architecture(self):
        """æ¶æ„è´¨é‡è¯„ä¼°"""
        assessments = []
        
        # 1. è¶…æ—¶æœºåˆ¶è¯„ä¼°
        has_timeout_protection = not any(t.get('timeout') for t in self.test_results)
        if has_timeout_protection:
            assessments.append("âœ… Timeout protection is working effectively")
        else:
            assessments.append("âŒ Timeout protection needs improvement")
        
        # 2. æ€§èƒ½ä¼˜åŒ–è¯„ä¼°
        people_test = next((t for t in self.test_results if 'People Daily' in t['name']), None)
        if people_test and people_test.get('success') and people_test.get('elapsed_time', 10) < 3:
            assessments.append("âœ… Critical performance issue resolved")
        else:
            assessments.append("âš ï¸  Performance optimization may need further work")
        
        # 3. å…¼å®¹æ€§è¯„ä¼°
        other_sites_ok = all(t.get('success') for t in self.test_results if 'People Daily' not in t['name'])
        if other_sites_ok:
            assessments.append("âœ… Backward compatibility maintained")
        else:
            assessments.append("âš ï¸  Some compatibility issues detected")
        
        # 4. ä»£ç è´¨é‡è¯„ä¼°
        assessments.append("ğŸ“‹ Code Quality Checklist:")
        assessments.append("  - Timeout mechanism: signal.alarm(5) implemented")
        assessments.append("  - Row limit: 50 rows max for tables")
        assessments.append("  - Cell limit: Implicit via row processing")
        assessments.append("  - Site-specific optimization: people.com.cn special handling")
        
        for assessment in assessments:
            print(f"  {assessment}")

if __name__ == '__main__':
    validator = PerformanceValidator()
    validator.run_validation_suite()