    4419 webfetcher.py
763:def fetch_html_with_curl_metrics(url: str, ua: Optional[str] = None, timeout: int = 30) -> tuple[str, FetchMetrics]:
818:def fetch_html_with_curl(url: str, ua: Optional[str] = None, timeout: int = 30) -> str:
26:import subprocess
219:    Validate URL and ensure safe encoding for subprocess calls.
228:        str: Safely encoded URL ready for curl/subprocess
769:        # Validate and encode URL for safe subprocess execution
782:        result = subprocess.run(cmd, capture_output=True, text=False, timeout=timeout+5)
804:    except subprocess.TimeoutExpired:
217:def validate_and_encode_url(url: str) -> str:
234:        >>> validate_and_encode_url('https://zh.wikipedia.org/wiki/中文')
236:        >>> validate_and_encode_url('https://example.com/path with spaces')
770:        validated_url = validate_and_encode_url(url)
4153:    url = validate_and_encode_url(args.url)
136-    primary_method: str = ""  # urllib/curl/playwright/local_file
137-    fallback_method: Optional[str] = None  # curl (when SSL fails)
138-    total_attempts: int = 0
139-    fetch_duration: float = 0.0
140-    render_duration: float = 0.0
141:    ssl_fallback_used: bool = False
142-    final_status: str = "unknown"  # success/failed
143-    error_message: Optional[str] = None
144-    
145-    def to_dict(self) -> Dict[str, Any]:
146-        """Convert metrics to dictionary for JSON serialization."""
--
148-            'primary_method': self.primary_method,
149-            'fallback_method': self.fallback_method,
150-            'total_attempts': self.total_attempts,
151-            'fetch_duration': round(self.fetch_duration, 3),
152-            'render_duration': round(self.render_duration, 3),
153:            'ssl_fallback_used': self.ssl_fallback_used,
154-            'final_status': self.final_status,
155-            'error_message': self.error_message
156-        }
157-    
158-    def get_summary(self) -> str:
--
166-            summary += f" | Attempts: {self.total_attempts}"
167-        
168-        if duration > 0:
169-            summary += f" | Duration: {duration:.2f}s"
170-        
171:        if self.ssl_fallback_used:
172:            summary += " | SSL fallback used"
173-            
174-        return summary
175-
176-
177-def add_metrics_to_markdown(md_content: str, metrics: FetchMetrics) -> str:
--
181-  Method: {metrics.primary_method}
182-  Fallback: {metrics.fallback_method or 'None'}
183-  Attempts: {metrics.total_attempts}
184-  Fetch Duration: {metrics.fetch_duration:.3f}s
185-  Render Duration: {metrics.render_duration:.3f}s
186:  SSL Fallback: {metrics.ssl_fallback_used}
187-  Status: {metrics.final_status}
188-  Error: {metrics.error_message or 'None'}
189--->
190-
191-"""
--
709-            # Call the original fetch_html function and track metrics
710-            html, fetch_metrics = fetch_html_original(url, ua, timeout)
711-            
712-            # Merge metrics from original fetch
713-            metrics.fetch_duration = time.time() - start_time
714:            metrics.ssl_fallback_used = fetch_metrics.ssl_fallback_used
715-            if fetch_metrics.fallback_method:
716-                metrics.fallback_method = fetch_metrics.fallback_method
717-            metrics.final_status = "success"
718-            
719-            return html, metrics
--
1001-            html = smart_decode(data, r)
1002-            metrics.final_status = "success"
1003-            return html, metrics
1004-            
1005-    except Exception as e:
1006:        # If SSL error, try curl as fallback
1007-        if "SSL" in str(e) or "CERTIFICATE" in str(e).upper():
1008-            logging.info(f"SSL error detected, falling back to curl for {url}")
1009-            html, curl_metrics = fetch_html_with_curl_metrics(url, ua, timeout)
1010-            
1011-            # Update metrics to reflect curl fallback
1012:            metrics.ssl_fallback_used = True
1013-            metrics.fallback_method = "curl"
1014-            metrics.final_status = curl_metrics.final_status
1015-            if curl_metrics.error_message:
1016-                metrics.error_message = curl_metrics.error_message
1017-            
=== FUNCTIONAL BASELINE TESTING RESULTS ===
Basic test (https://example.com): SUCCESS - Output: /tmp/test_basic_phase1.md/2025-09-29-165728 - Example Domain.md
SSL test (https://self-signed.badssl.com/): SUCCESS - Output: /tmp/test_ssl_phase1.md/2025-09-29-165737 - self-signed.badssl.com.md
=== DEPENDENCY ANALYSIS ===
782:        result = subprocess.run(cmd, capture_output=True, text=False, timeout=timeout+5)
804:    except subprocess.TimeoutExpired:
763:def fetch_html_with_curl_metrics(url: str, ua: Optional[str] = None, timeout: int = 30) -> tuple[str, FetchMetrics]:
818:def fetch_html_with_curl(url: str, ua: Optional[str] = None, timeout: int = 30) -> str:
820:    html, _ = fetch_html_with_curl_metrics(url, ua, timeout)
1009:            html, curl_metrics = fetch_html_with_curl_metrics(url, ua, timeout)
# Safari integration removed - using urllib/curl only
    primary_method: str = ""  # urllib/curl/playwright/local_file
    fallback_method: Optional[str] = None  # curl (when SSL fails)
        str: Safely encoded URL ready for curl/subprocess
    """Fallback to curl for sites with SSL issues with metrics tracking"""
    metrics = FetchMetrics(primary_method="curl")
            'curl', '-k', '-s', '-L',  # -k ignores SSL, -s silent, -L follow redirects
        logging.debug(f"Executing curl command for URL: {validated_url}")
            # 使用智能解码处理curl获取的字节数据
            # Log curl error details for debugging
            error_msg = f"curl failed with code {result.returncode}: {result.stderr}"
            logging.error(f"curl failed for {validated_url}: return code {result.returncode}, stderr: {result.stderr}")
        error_msg = f"Invalid URL for curl: {e}"
        logging.error(f"URL validation failed for curl: {e}")
        error_msg = f"curl timeout for {url}"
        error_msg = f"Failed to fetch with curl from {url}: {e}"
    """Fallback to curl for sites with SSL issues (legacy interface)"""
    html, _ = fetch_html_with_curl_metrics(url, ua, timeout)
    Fetch HTML using urllib with optional curl fallback for SSL issues.
        # If SSL error, try curl as fallback
            logging.info(f"SSL error detected, falling back to curl for {url}")
            html, curl_metrics = fetch_html_with_curl_metrics(url, ua, timeout)
            # Update metrics to reflect curl fallback
            metrics.fallback_method = "curl"
            metrics.final_status = curl_metrics.final_status
            if curl_metrics.error_message:
                metrics.error_message = curl_metrics.error_message
# Public interface - using direct urllib/curl with retry fallback
=== PHASE 1 COMPLETION SUMMARY ===
✓ Backup created: webfetcher.py.backup.curl
✓ Total lines: 4419
✓ Curl functions identified: 2 (fetch_html_with_curl_metrics, fetch_html_with_curl)
✓ Subprocess usage: 2 locations (subprocess.run, subprocess.TimeoutExpired)
✓ Functional tests: Both basic and SSL tests successful
✓ Curl references: 27 total occurrences found
