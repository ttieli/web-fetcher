#!/usr/bin/env python3
"""
QCC Extractor for Safari-based Content Extraction
================================================

Site-specific extractor for QCC (ä¼æŸ¥æŸ¥) website content.
Handles Chinese business information extraction with specialized
parsing for QCC company profile structure.

Author: Web_Fetcher Team
Version: 1.0.0
"""

import re
import json
from typing import Dict
from bs4 import BeautifulSoup
from datetime import datetime
from .base_extractor import BaseExtractor

class QCCExtractor(BaseExtractor):
    """
    QCC-specific Safari content extractor.
    
    Specialized for extracting content from qcc.com with
    knowledge of QCC page structure and business data patterns.
    """
    
    def parse_content(self, html_content: str) -> Dict[str, str]:
        """
        Parse QCC-specific content from HTML.
        
        Args:
            html_content (str): Raw HTML content from Safari
            
        Returns:
            Dict[str, str]: Parsed content with QCC-specific structure
        """
        self.logger.info("Parsing QCC content...")
        
        article = {
            'title': '',
            'content': '',
            'company_name': '',
            'company_status': '',
            'registration_number': '',
            'legal_representative': '',
            'registered_capital': '',
            'establishment_date': '',
            'business_scope': '',
            'address': '',
            'contact_info': '',
            'industry': '',
            'company_type': ''
        }
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Extract company name (title)
            title_selectors = [
                'h1.company-name',       # QCC company name class
                'h1',                    # Standard h1
                '.company-title',        # Company title class
                '.enterprise-name',      # Enterprise name
                '.firm-name',            # Firm name
                'title',                 # Page title fallback
                '[class*="name"]'        # Any class containing "name"
            ]
            
            for selector in title_selectors:
                title_elem = soup.select_one(selector)
                if title_elem:
                    title_text = title_elem.get_text(strip=True)
                    # Validate title quality (avoid CAPTCHA pages)
                    if (len(title_text) > 2 and 
                        'éªŒè¯' not in title_text and 
                        'CAPTCHA' not in title_text and
                        'æ»‘åŠ¨' not in title_text and
                        'é”™è¯¯' not in title_text):
                        article['title'] = title_text
                        article['company_name'] = title_text
                        self.logger.info(f"Company name found via {selector}: {title_text}")
                        break
            
            # Extract main content - QCC has structured data
            content_parts = []
            
            # Try to extract structured company information
            info_selectors = [
                '.company-info',         # Company info section
                '.enterprise-info',      # Enterprise info
                '.basic-info',           # Basic information
                '.company-detail',       # Company details
                '.firm-info',            # Firm information
                'main',                  # Main content area
                '.content'               # Generic content
            ]
            
            main_content = ""
            for selector in info_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    # Clean unwanted elements
                    elem_copy = content_elem.__copy__()
                    for unwanted in elem_copy(['script', 'style', 'nav', 'header', 
                                              'footer', 'aside', '.advertisement',
                                              '.ad', '.share', '.social']):
                        unwanted.decompose()
                    
                    content_text = elem_copy.get_text(strip=True, separator='\n')
                    if len(content_text) > len(main_content):
                        main_content = content_text
            
            # Extract specific business data fields
            self._extract_business_fields(soup, article)
            
            # Build comprehensive content from extracted fields
            if article['company_name']:
                content_parts.append(f"ä¼ä¸šåç§°ï¼š{article['company_name']}")
            
            if article['company_status']:
                content_parts.append(f"ä¼ä¸šçŠ¶æ€ï¼š{article['company_status']}")
            
            if article['legal_representative']:
                content_parts.append(f"æ³•å®šä»£è¡¨äººï¼š{article['legal_representative']}")
            
            if article['registered_capital']:
                content_parts.append(f"æ³¨å†Œèµ„æœ¬ï¼š{article['registered_capital']}")
            
            if article['establishment_date']:
                content_parts.append(f"æˆç«‹æ—¥æœŸï¼š{article['establishment_date']}")
            
            if article['registration_number']:
                content_parts.append(f"ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç ï¼š{article['registration_number']}")
            
            if article['company_type']:
                content_parts.append(f"ä¼ä¸šç±»å‹ï¼š{article['company_type']}")
            
            if article['industry']:
                content_parts.append(f"æ‰€å±è¡Œä¸šï¼š{article['industry']}")
            
            if article['address']:
                content_parts.append(f"æ³¨å†Œåœ°å€ï¼š{article['address']}")
            
            if article['business_scope']:
                content_parts.append(f"ç»è¥èŒƒå›´ï¼š{article['business_scope']}")
            
            # Combine structured data with main content
            if content_parts:
                structured_content = '\n\n'.join(content_parts)
                if main_content and main_content not in structured_content:
                    article['content'] = structured_content + '\n\n' + main_content
                else:
                    article['content'] = structured_content
            else:
                article['content'] = main_content
            
            # Fallback title extraction
            if not article['title']:
                title_elem = soup.find('title')
                if title_elem:
                    page_title = title_elem.get_text(strip=True)
                    # Clean up QCC page title
                    page_title = re.sub(r'\s*[-|_]\s*(ä¼æŸ¥æŸ¥|qcc\.com).*$', '', page_title)
                    if len(page_title) > 2:
                        article['title'] = page_title
                        if not article['company_name']:
                            article['company_name'] = page_title
                        self.logger.info("Using cleaned page title as fallback")
            
            content_length = len(article['content'])
            self.logger.info(f"QCC parsing results:")
            self.logger.info(f"  Company: {article['company_name']}")
            self.logger.info(f"  Content: {content_length} characters")
            self.logger.info(f"  Status: {article['company_status']}")
            
        except Exception as e:
            self.logger.error(f"QCC content parsing error: {e}")
        
        return article
    
    def _extract_business_fields(self, soup: BeautifulSoup, article: Dict[str, str]):
        """Extract specific business information fields from QCC page."""
        try:
            # Look for structured data in various formats
            
            # Method 1: Try JSON-LD structured data
            json_scripts = soup.find_all('script', type='application/ld+json')
            for script in json_scripts:
                try:
                    data = json.loads(script.string)
                    if isinstance(data, dict):
                        if 'name' in data and not article['company_name']:
                            article['company_name'] = data['name']
                        if 'legalName' in data and not article['company_name']:
                            article['company_name'] = data['legalName']
                        if 'address' in data and not article['address']:
                            if isinstance(data['address'], dict):
                                article['address'] = data['address'].get('streetAddress', '')
                            else:
                                article['address'] = str(data['address'])
                except json.JSONDecodeError:
                    continue
            
            # Method 2: Look for specific data fields with common patterns
            field_patterns = {
                'company_status': [r'ä¼ä¸šçŠ¶æ€[ï¼š:\s]*([^ï¼‰\n]+)', r'çŠ¶æ€[ï¼š:\s]*([^ï¼‰\n]+)'],
                'legal_representative': [r'æ³•å®šä»£è¡¨äºº[ï¼š:\s]*([^ï¼‰\n]+)', r'æ³•äºº[ï¼š:\s]*([^ï¼‰\n]+)'],
                'registered_capital': [r'æ³¨å†Œèµ„æœ¬[ï¼š:\s]*([^ï¼‰\n]+)', r'èµ„æœ¬[ï¼š:\s]*([^ï¼‰\n]+ä¸‡å…ƒ)'],
                'establishment_date': [r'æˆç«‹æ—¥æœŸ[ï¼š:\s]*([0-9\-å¹´æœˆæ—¥]+)', r'æˆç«‹æ—¶é—´[ï¼š:\s]*([0-9\-å¹´æœˆæ—¥]+)'],
                'registration_number': [r'ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç [ï¼š:\s]*([A-Z0-9]+)', r'æ³¨å†Œå·[ï¼š:\s]*([A-Z0-9]+)'],
                'company_type': [r'ä¼ä¸šç±»å‹[ï¼š:\s]*([^ï¼‰\n]+)', r'å…¬å¸ç±»å‹[ï¼š:\s]*([^ï¼‰\n]+)'],
                'industry': [r'æ‰€å±è¡Œä¸š[ï¼š:\s]*([^ï¼‰\n]+)', r'è¡Œä¸š[ï¼š:\s]*([^ï¼‰\n]+)']
            }
            
            page_text = soup.get_text()
            for field, patterns in field_patterns.items():
                if not article[field]:  # Only extract if not already found
                    for pattern in patterns:
                        match = re.search(pattern, page_text)
                        if match:
                            article[field] = match.group(1).strip()
                            break
            
            # Method 3: Look for specific CSS classes or data attributes
            field_selectors = {
                'company_status': ['.company-status', '.status', '[data-status]'],
                'legal_representative': ['.legal-person', '.legal-rep', '.representative'],
                'registered_capital': ['.capital', '.register-capital', '.reg-capital'],
                'establishment_date': ['.establish-date', '.found-date', '.create-date'],
                'registration_number': ['.credit-code', '.reg-number', '.license-number'],
                'address': ['.address', '.company-address', '.reg-address'],
                'business_scope': ['.business-scope', '.scope', '.business-range']
            }
            
            for field, selectors in field_selectors.items():
                if not article[field]:  # Only extract if not already found
                    for selector in selectors:
                        elem = soup.select_one(selector)
                        if elem:
                            text = elem.get_text(strip=True)
                            if len(text) > 0 and len(text) < 500:  # Reasonable length
                                article[field] = text
                                break
            
            # Extract business scope (often longer text)
            if not article['business_scope']:
                scope_patterns = [r'ç»è¥èŒƒå›´[ï¼š:\s]*([^ã€‚\n]{20,})', r'ä¸šåŠ¡èŒƒå›´[ï¼š:\s]*([^ã€‚\n]{20,})']
                for pattern in scope_patterns:
                    match = re.search(pattern, page_text)
                    if match:
                        scope_text = match.group(1).strip()
                        if len(scope_text) > 10:
                            article['business_scope'] = scope_text
                            break
            
        except Exception as e:
            self.logger.warning(f"Error extracting business fields: {e}")
    
    def format_output(self, parsed_content: Dict[str, str]) -> str:
        """
        Format parsed QCC content for output.
        
        Args:
            parsed_content (Dict[str, str]): Parsed content
            
        Returns:
            str: Formatted markdown content
        """
        self.logger.info("Formatting QCC content as markdown...")
        
        # Prepare data
        company_name = parsed_content.get('company_name', parsed_content.get('title', 'ä¼ä¸šä¿¡æ¯'))
        content = parsed_content.get('content', '')
        
        # Format extraction time
        extraction_time = self.extraction_time.strftime("%Y-%m-%d %H:%M:%S")
        
        # Build markdown content
        markdown_parts = []
        
        # Title
        markdown_parts.append(f"# {company_name}")
        markdown_parts.append("")
        
        # Metadata section
        markdown_parts.extend([
            "## ä¼ä¸šåŸºæœ¬ä¿¡æ¯",
            "",
            f"**æºé“¾æ¥:** {self.url}",
            f"**æå–æ—¶é—´:** {extraction_time}",
            f"**æå–æ–¹æ³•:** Safariè‡ªåŠ¨åŒ–æå– (QCCä¸“ç”¨)",
            ""
        ])
        
        # Business information table
        business_info = []
        info_fields = [
            ('ä¼ä¸šåç§°', 'company_name'),
            ('ä¼ä¸šçŠ¶æ€', 'company_status'),
            ('æ³•å®šä»£è¡¨äºº', 'legal_representative'),
            ('æ³¨å†Œèµ„æœ¬', 'registered_capital'),
            ('æˆç«‹æ—¥æœŸ', 'establishment_date'),
            ('ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç ', 'registration_number'),
            ('ä¼ä¸šç±»å‹', 'company_type'),
            ('æ‰€å±è¡Œä¸š', 'industry'),
            ('æ³¨å†Œåœ°å€', 'address')
        ]
        
        for label, field in info_fields:
            value = parsed_content.get(field, '').strip()
            if value:
                business_info.append(f"| {label} | {value} |")
        
        if business_info:
            markdown_parts.extend([
                "### ä¼ä¸šè¯¦æƒ…",
                "",
                "| é¡¹ç›® | å†…å®¹ |",
                "|------|------|"
            ])
            markdown_parts.extend(business_info)
            markdown_parts.append("")
        
        # Business scope section
        business_scope = parsed_content.get('business_scope', '').strip()
        if business_scope:
            markdown_parts.extend([
                "### ç»è¥èŒƒå›´",
                "",
                business_scope,
                ""
            ])
        
        # Separator
        markdown_parts.append("---")
        markdown_parts.append("")
        
        # Additional content
        if content and content.strip():
            markdown_parts.extend([
                "## è¯¦ç»†ä¿¡æ¯",
                "",
                content.strip(),
                ""
            ])
        
        # Footer
        markdown_parts.extend([
            "---",
            "",
            "*æ­¤æ–‡æ¡£ç”±Web_Fetcher Safariæå–ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*",
            f"*æå–å™¨: QCCExtractor | æå–æ—¶é—´: {extraction_time}*",
            "*æ•°æ®æ¥æº: ä¼æŸ¥æŸ¥ (qcc.com)*"
        ])
        
        markdown_content = "\n".join(markdown_parts)
        
        self.logger.info(f"Formatted QCC markdown: {len(markdown_content)} characters")
        
        return markdown_content

# Testing
if __name__ == "__main__":
    import logging
    
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Test URL
    test_url = "https://www.qcc.com/firm/abc123test"
    
    print(f"Testing QCC Extractor with URL: {test_url}")
    print("=" * 60)
    
    extractor = QCCExtractor(test_url)
    
    try:
        success, content, metadata = extractor.extract()
        
        if success:
            print("âœ… QCC extraction successful!")
            print(f"Content length: {len(content)} characters")
            print(f"Metadata: {metadata}")
            
            # Save test output
            output_file = f"/tmp/qcc_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"Test output saved to: {output_file}")
        else:
            print("âŒ QCC extraction failed!")
            print(f"Error: {content}")
            
    except Exception as e:
        print(f"ğŸ’¥ Test failed with exception: {e}")
    
    print("=" * 60)
    print("QCC extractor testing completed")